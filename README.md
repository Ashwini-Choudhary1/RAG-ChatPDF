# RAG-ChatPDF
RAG-ChatPDF is a local Retrieval-Augmented Generation (RAG) system designed for querying academic research papers and full PDF documents.

By storing semantic representations in a vector database, the system ensures that the Large Language Model (LLM) generates answers grounded strictly in your document content, eliminating hallucinations and overcoming context window limits.

# Project Structure

# ðŸ“‚ Project Structure

```
RAG-ChatPDF/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw_pdfs/           # Original PDF documents
â”‚   â”œâ”€â”€ processed/
â”‚   â”‚   â”œâ”€â”€ extracted_text/ # Raw extracted text
â”‚   â”‚   â””â”€â”€ cleaned_text/   # Cleaned text (after preprocessing)
â”‚   â””â”€â”€ metadata/           # Paper metadata
â”‚
â”œâ”€â”€ ingest/
â”‚   â”œâ”€â”€ pdf_loader.py       # PDF text extraction
â”‚   â”œâ”€â”€ text_cleaner.py     # Cleaning & safety filtering
â”‚   â””â”€â”€ chunker.py          # Semantic chunking (Coming Soon)
â”‚
â”œâ”€â”€ embeddings/
â”‚   â””â”€â”€ embedder.py         # Text â†’ vector embeddings
â”‚
â”œâ”€â”€ vectorstore/
â”‚   â””â”€â”€ faiss_store.py      # FAISS vector database logic
â”‚
â”œâ”€â”€ rag/
â”‚   â”œâ”€â”€ retriever.py        # Vector similarity retrieval
â”‚   â”œâ”€â”€ prompt.py           # Prompt grounding logic
â”‚   â””â”€â”€ generator.py        # LLM interface abstraction
â”‚
â”œâ”€â”€ api/
â”‚   â””â”€â”€ main.py             # FastAPI backend
â”‚
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â””â”€â”€ .gitignore

PDF â†’ Extraction â†’ Cleaning â†’ Chunking â†’ Embeddings â†’ FAISS
                                                     â†“
                                              Retriever
                                                     â†“
                                               Generator (LLM)
                                                     â†“
                                             FastAPI (Streaming)
```

# Why RAG-ChatPDF?
Standard LLMs face several hurdles when dealing with specific research:

Static Memory: They cannot "remember" my private or local PDFs.

Hallucinations: They may invent facts about niche academic topics.

Context Limits: They cannot process hundreds of pages at once.

Scalability: They struggle with large-scale document collections.

# RAG-ChatPDF solves this by:

Keeping documents stored efficiently outside the LLM.

Retrieving only the most relevant sections for every query.

Injecting knowledge dynamically at runtime.

Producing grounded, explainable answers with source attribution.






